{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, LSTM, MaxPooling1D\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pp_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52599</th>\n",
       "      <td>Job Security/Advancement</td>\n",
       "      <td>good opportunities for career growth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69969</th>\n",
       "      <td>tech_product</td>\n",
       "      <td>no ego problem solving is mandatory across the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101786</th>\n",
       "      <td>tech_product</td>\n",
       "      <td>schibsted has a broad tech stack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6968</th>\n",
       "      <td>culture_team</td>\n",
       "      <td>a self starter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393294</th>\n",
       "      <td>haras_discrim_sexism</td>\n",
       "      <td>a great deal of effort has gone into gender di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48187</th>\n",
       "      <td>wlb_working_conditions</td>\n",
       "      <td>work life balance is generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86026</th>\n",
       "      <td>tech_product</td>\n",
       "      <td>type of problems to be solved are unlike anyth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            label  \\\n",
       "52599    Job Security/Advancement   \n",
       "69969                tech_product   \n",
       "101786               tech_product   \n",
       "6968                 culture_team   \n",
       "1393294      haras_discrim_sexism   \n",
       "48187      wlb_working_conditions   \n",
       "86026                tech_product   \n",
       "\n",
       "                                                   pp_sent  \n",
       "52599                 good opportunities for career growth  \n",
       "69969    no ego problem solving is mandatory across the...  \n",
       "101786                    schibsted has a broad tech stack  \n",
       "6968                                        a self starter  \n",
       "1393294  a great deal of effort has gone into gender di...  \n",
       "48187                  work life balance is generally good  \n",
       "86026    type of problems to be solved are unlike anyth...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pkl.load(open(\"gdr_assignment_labelled.pkl\",\"rb\"))\n",
    "\n",
    "## un-list the label column\n",
    "\n",
    "raw_data['label'] = raw_data['label'].apply(lambda x: x[0])\n",
    "raw_data.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 2)\n",
      "Job Security/Advancement       1113\n",
      "management                     1039\n",
      "salary_benefits                1018\n",
      "culture_team                   1010\n",
      "haras_discrim_sexism           1001\n",
      "wlb_working_conditions          997\n",
      "tech_product                    983\n",
      "business_vision_competitors     839\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Distribution of label class in raw dataset')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1166f4c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## shape of training data\n",
    "print(raw_data.shape)\n",
    "\n",
    "## count of labels in dataset\n",
    "\n",
    "print(raw_data['label'].value_counts())\n",
    "\n",
    "### distribution of labels in training set\n",
    "\n",
    "sns.set_color_codes()\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1, figsize = (18,6))\n",
    "\n",
    "sns.countplot('label', data = raw_data,palette=\"Set2\", ax = ax1)\n",
    "ax1.set_xlabel(\"label\", size = 15)\n",
    "plt.title(\"Distribution of label class in raw dataset\", size = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "## check max length of sequence in pp_sent\n",
    "print(max(raw_data['pp_sent'].apply(lambda x: len(x.split()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre- process data\n",
    "\n",
    "- convert labels to one-hot vectors\n",
    "- convert pp_sent to numerical form and pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 3797\n",
      "padded_docs: 8000\n"
     ]
    }
   ],
   "source": [
    "## process labels- label encoding\n",
    "le = LabelEncoder()\n",
    "labels_int = le.fit_transform(raw_data['label'].values)\n",
    "labels = to_categorical(labels_int)\n",
    "\n",
    "### prepare tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(raw_data['pp_sent'].values)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print(\"vocab size:\",vocab_size)\n",
    "\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(raw_data['pp_sent'].values)\n",
    "# pad documents to a max length of 44 words\n",
    "max_length = 44\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(\"padded_docs:\",len(padded_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1- sequential model with convolution\n",
    "\n",
    "- Here we also learn embedding layer weights based on training data\n",
    "- Multi- class classification with 8 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 44, 10)            37970     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 44, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 42, 64)            1984      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 2056      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 58,650\n",
      "Trainable params: 58,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/50\n",
      "6400/6400 [==============================] - 4s 674us/step - loss: 1.0314 - acc: 0.6473 - val_loss: 0.3034 - val_acc: 0.9156\n",
      "Epoch 2/50\n",
      "6400/6400 [==============================] - 4s 566us/step - loss: 0.1791 - acc: 0.9483 - val_loss: 0.1633 - val_acc: 0.9562\n",
      "Epoch 3/50\n",
      "6400/6400 [==============================] - 4s 565us/step - loss: 0.0894 - acc: 0.9742 - val_loss: 0.1444 - val_acc: 0.9619\n",
      "Epoch 4/50\n",
      "6400/6400 [==============================] - 4s 598us/step - loss: 0.0565 - acc: 0.9830 - val_loss: 0.1441 - val_acc: 0.9656\n",
      "Epoch 5/50\n",
      "6400/6400 [==============================] - 4s 556us/step - loss: 0.0389 - acc: 0.9884 - val_loss: 0.1567 - val_acc: 0.9606\n",
      "Epoch 6/50\n",
      "6400/6400 [==============================] - 4s 557us/step - loss: 0.0305 - acc: 0.9906 - val_loss: 0.1445 - val_acc: 0.9612\n",
      "Epoch 7/50\n",
      "6400/6400 [==============================] - 4s 561us/step - loss: 0.0275 - acc: 0.9928 - val_loss: 0.1547 - val_acc: 0.9650\n",
      "Epoch 8/50\n",
      "6400/6400 [==============================] - 4s 565us/step - loss: 0.0240 - acc: 0.9933 - val_loss: 0.1641 - val_acc: 0.9637\n",
      "Epoch 9/50\n",
      "6400/6400 [==============================] - 4s 565us/step - loss: 0.0216 - acc: 0.9936 - val_loss: 0.1500 - val_acc: 0.9669\n",
      "Epoch 10/50\n",
      "6400/6400 [==============================] - 4s 563us/step - loss: 0.0206 - acc: 0.9928 - val_loss: 0.1418 - val_acc: 0.9662\n",
      "Epoch 11/50\n",
      "6400/6400 [==============================] - 4s 568us/step - loss: 0.0175 - acc: 0.9942 - val_loss: 0.1632 - val_acc: 0.9662\n",
      "Epoch 12/50\n",
      "6400/6400 [==============================] - 4s 628us/step - loss: 0.0179 - acc: 0.9944 - val_loss: 0.1802 - val_acc: 0.9637\n",
      "Epoch 13/50\n",
      "6400/6400 [==============================] - 4s 577us/step - loss: 0.0134 - acc: 0.9961 - val_loss: 0.1654 - val_acc: 0.9637\n",
      "Epoch 14/50\n",
      "6400/6400 [==============================] - 4s 587us/step - loss: 0.0125 - acc: 0.9956 - val_loss: 0.1599 - val_acc: 0.9681\n",
      "Epoch 15/50\n",
      "6400/6400 [==============================] - 4s 569us/step - loss: 0.0153 - acc: 0.9950 - val_loss: 0.1686 - val_acc: 0.9681\n",
      "Epoch 16/50\n",
      "6400/6400 [==============================] - 4s 573us/step - loss: 0.0191 - acc: 0.9942 - val_loss: 0.1448 - val_acc: 0.9725\n",
      "Epoch 17/50\n",
      "6400/6400 [==============================] - 4s 574us/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.1602 - val_acc: 0.9719\n",
      "Epoch 18/50\n",
      "6400/6400 [==============================] - 4s 622us/step - loss: 0.0144 - acc: 0.9959 - val_loss: 0.1552 - val_acc: 0.9675\n",
      "Epoch 19/50\n",
      "6400/6400 [==============================] - 4s 584us/step - loss: 0.0105 - acc: 0.9962 - val_loss: 0.1595 - val_acc: 0.9744\n",
      "Epoch 20/50\n",
      "6400/6400 [==============================] - 4s 583us/step - loss: 0.0110 - acc: 0.9961 - val_loss: 0.1747 - val_acc: 0.9687\n",
      "Epoch 21/50\n",
      "6400/6400 [==============================] - 4s 685us/step - loss: 0.0173 - acc: 0.9959 - val_loss: 0.1664 - val_acc: 0.9719\n",
      "Epoch 22/50\n",
      "6400/6400 [==============================] - 4s 610us/step - loss: 0.0116 - acc: 0.9964 - val_loss: 0.1531 - val_acc: 0.9694\n",
      "Epoch 23/50\n",
      "6400/6400 [==============================] - 5s 783us/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.1611 - val_acc: 0.9719\n",
      "Epoch 24/50\n",
      "6400/6400 [==============================] - 4s 596us/step - loss: 0.0116 - acc: 0.9966 - val_loss: 0.1576 - val_acc: 0.9719\n",
      "Epoch 25/50\n",
      "6400/6400 [==============================] - 4s 619us/step - loss: 0.0112 - acc: 0.9961 - val_loss: 0.1719 - val_acc: 0.9719\n",
      "Epoch 26/50\n",
      "6400/6400 [==============================] - 5s 758us/step - loss: 0.0134 - acc: 0.9955 - val_loss: 0.1672 - val_acc: 0.9687\n",
      "Epoch 27/50\n",
      "6400/6400 [==============================] - 4s 639us/step - loss: 0.0098 - acc: 0.9967 - val_loss: 0.1752 - val_acc: 0.9681\n",
      "Epoch 28/50\n",
      "6400/6400 [==============================] - 4s 622us/step - loss: 0.0073 - acc: 0.9980 - val_loss: 0.1895 - val_acc: 0.9694\n",
      "Epoch 29/50\n",
      "6400/6400 [==============================] - 4s 566us/step - loss: 0.0127 - acc: 0.9969 - val_loss: 0.1731 - val_acc: 0.9712\n",
      "Epoch 30/50\n",
      "6400/6400 [==============================] - 4s 568us/step - loss: 0.0126 - acc: 0.9964 - val_loss: 0.1692 - val_acc: 0.9700\n",
      "Epoch 31/50\n",
      "6400/6400 [==============================] - 4s 596us/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.1625 - val_acc: 0.9725\n",
      "Epoch 32/50\n",
      "6400/6400 [==============================] - 5s 774us/step - loss: 0.0094 - acc: 0.9972 - val_loss: 0.1725 - val_acc: 0.9706\n",
      "Epoch 33/50\n",
      "6400/6400 [==============================] - 5s 721us/step - loss: 0.0091 - acc: 0.9975 - val_loss: 0.1565 - val_acc: 0.9700\n",
      "Epoch 34/50\n",
      "6400/6400 [==============================] - 4s 623us/step - loss: 0.0095 - acc: 0.9964 - val_loss: 0.1814 - val_acc: 0.9687\n",
      "Epoch 35/50\n",
      "6400/6400 [==============================] - 4s 637us/step - loss: 0.0041 - acc: 0.9981 - val_loss: 0.1818 - val_acc: 0.9706\n",
      "Epoch 36/50\n",
      "6400/6400 [==============================] - 4s 651us/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.1908 - val_acc: 0.9712\n",
      "Epoch 37/50\n",
      "6400/6400 [==============================] - 4s 595us/step - loss: 0.0076 - acc: 0.9981 - val_loss: 0.1683 - val_acc: 0.9719\n",
      "Epoch 38/50\n",
      "6400/6400 [==============================] - 4s 599us/step - loss: 0.0061 - acc: 0.9978 - val_loss: 0.1867 - val_acc: 0.9719\n",
      "Epoch 39/50\n",
      "6400/6400 [==============================] - 4s 599us/step - loss: 0.0133 - acc: 0.9967 - val_loss: 0.1855 - val_acc: 0.9656\n",
      "Epoch 40/50\n",
      "6400/6400 [==============================] - 4s 630us/step - loss: 0.0111 - acc: 0.9967 - val_loss: 0.1937 - val_acc: 0.9687\n",
      "Epoch 41/50\n",
      "6400/6400 [==============================] - 4s 619us/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.1937 - val_acc: 0.9694\n",
      "Epoch 42/50\n",
      "6400/6400 [==============================] - 4s 626us/step - loss: 0.0102 - acc: 0.9977 - val_loss: 0.1853 - val_acc: 0.9700\n",
      "Epoch 43/50\n",
      "6400/6400 [==============================] - 4s 621us/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.1811 - val_acc: 0.9700\n",
      "Epoch 44/50\n",
      "6400/6400 [==============================] - 4s 645us/step - loss: 0.0067 - acc: 0.9981 - val_loss: 0.1989 - val_acc: 0.9694\n",
      "Epoch 45/50\n",
      "6400/6400 [==============================] - 4s 604us/step - loss: 0.0067 - acc: 0.9981 - val_loss: 0.1934 - val_acc: 0.9687\n",
      "Epoch 46/50\n",
      "6400/6400 [==============================] - 4s 593us/step - loss: 0.0078 - acc: 0.9977 - val_loss: 0.2001 - val_acc: 0.9681\n",
      "Epoch 47/50\n",
      "6400/6400 [==============================] - 4s 594us/step - loss: 0.0078 - acc: 0.9975 - val_loss: 0.1800 - val_acc: 0.9725\n",
      "Epoch 48/50\n",
      "6400/6400 [==============================] - 4s 667us/step - loss: 0.0067 - acc: 0.9981 - val_loss: 0.1591 - val_acc: 0.9750\n",
      "Epoch 49/50\n",
      "6400/6400 [==============================] - 4s 626us/step - loss: 0.0087 - acc: 0.9972 - val_loss: 0.1828 - val_acc: 0.9719\n",
      "Epoch 50/50\n",
      "6400/6400 [==============================] - 4s 680us/step - loss: 0.0072 - acc: 0.9987 - val_loss: 0.1935 - val_acc: 0.9737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f5e7d30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(vocab_size,10,input_length=max_length))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Conv1D(64,3,padding='valid',activation='relu',strides=1))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(256))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dense(8))\n",
    "model1.add(Activation('softmax'))\n",
    "print(model1.summary())\n",
    "model1.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "\n",
    "#train -test split- split into 80% for train and 20% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, labels, test_size=0.20,\n",
    "                                                    random_state=5678, stratify =labels)\n",
    "\n",
    "# fit the model\n",
    "model1.fit(X_train, y_train, epochs=50,batch_size = 10,validation_data=(X_test,y_test))\n",
    "\n",
    "# loss1, accuracy1 = model1.evaluate(padded_docs,labels, verbose=0)\n",
    "# print(\"Accuracy:\", accuracy1*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model2 -  Using pre trained- Glove 50- D word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n",
      "(3797, 50)\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.50d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded {0} word vectors.'.format(len(embeddings_index)))\n",
    "\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 50))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 44, 50)            189850    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 44, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 42, 64)            9664      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 2056      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 218,210\n",
      "Trainable params: 28,360\n",
      "Non-trainable params: 189,850\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/50\n",
      "6400/6400 [==============================] - 3s 514us/step - loss: 0.9541 - acc: 0.6836 - val_loss: 0.4902 - val_acc: 0.8362\n",
      "Epoch 2/50\n",
      "6400/6400 [==============================] - 3s 423us/step - loss: 0.4721 - acc: 0.8486 - val_loss: 0.3609 - val_acc: 0.8869\n",
      "Epoch 3/50\n",
      "6400/6400 [==============================] - 3s 419us/step - loss: 0.3666 - acc: 0.8802 - val_loss: 0.2984 - val_acc: 0.9062\n",
      "Epoch 4/50\n",
      "6400/6400 [==============================] - 3s 425us/step - loss: 0.2863 - acc: 0.9069 - val_loss: 0.2541 - val_acc: 0.9156\n",
      "Epoch 5/50\n",
      "6400/6400 [==============================] - 3s 425us/step - loss: 0.2482 - acc: 0.9233 - val_loss: 0.2335 - val_acc: 0.9231\n",
      "Epoch 6/50\n",
      "6400/6400 [==============================] - 3s 426us/step - loss: 0.2180 - acc: 0.9298 - val_loss: 0.2225 - val_acc: 0.9300\n",
      "Epoch 7/50\n",
      "6400/6400 [==============================] - 3s 427us/step - loss: 0.2009 - acc: 0.9339 - val_loss: 0.1968 - val_acc: 0.9356\n",
      "Epoch 8/50\n",
      "6400/6400 [==============================] - 3s 485us/step - loss: 0.1709 - acc: 0.9420 - val_loss: 0.2352 - val_acc: 0.9262\n",
      "Epoch 9/50\n",
      "6400/6400 [==============================] - 3s 425us/step - loss: 0.1615 - acc: 0.9469 - val_loss: 0.2169 - val_acc: 0.9387\n",
      "Epoch 10/50\n",
      "6400/6400 [==============================] - 3s 425us/step - loss: 0.1647 - acc: 0.9447 - val_loss: 0.1934 - val_acc: 0.9450\n",
      "Epoch 11/50\n",
      "6400/6400 [==============================] - 3s 473us/step - loss: 0.1472 - acc: 0.9514 - val_loss: 0.1762 - val_acc: 0.9412\n",
      "Epoch 12/50\n",
      "6400/6400 [==============================] - 3s 538us/step - loss: 0.1366 - acc: 0.9552 - val_loss: 0.1954 - val_acc: 0.9319\n",
      "Epoch 13/50\n",
      "6400/6400 [==============================] - 3s 480us/step - loss: 0.1261 - acc: 0.9591 - val_loss: 0.1750 - val_acc: 0.9475\n",
      "Epoch 14/50\n",
      "6400/6400 [==============================] - 3s 454us/step - loss: 0.1231 - acc: 0.9595 - val_loss: 0.1722 - val_acc: 0.9525\n",
      "Epoch 15/50\n",
      "6400/6400 [==============================] - 3s 497us/step - loss: 0.1247 - acc: 0.9566 - val_loss: 0.1693 - val_acc: 0.9469\n",
      "Epoch 16/50\n",
      "6400/6400 [==============================] - 3s 408us/step - loss: 0.0995 - acc: 0.9664 - val_loss: 0.1916 - val_acc: 0.9444\n",
      "Epoch 17/50\n",
      "6400/6400 [==============================] - 3s 408us/step - loss: 0.1045 - acc: 0.9645 - val_loss: 0.1872 - val_acc: 0.9487\n",
      "Epoch 18/50\n",
      "6400/6400 [==============================] - 3s 413us/step - loss: 0.1011 - acc: 0.9664 - val_loss: 0.1960 - val_acc: 0.9462\n",
      "Epoch 19/50\n",
      "6400/6400 [==============================] - 4s 549us/step - loss: 0.1056 - acc: 0.9658 - val_loss: 0.1720 - val_acc: 0.9475\n",
      "Epoch 20/50\n",
      "6400/6400 [==============================] - 3s 462us/step - loss: 0.0958 - acc: 0.9702 - val_loss: 0.1643 - val_acc: 0.9512\n",
      "Epoch 21/50\n",
      "6400/6400 [==============================] - 3s 426us/step - loss: 0.0880 - acc: 0.9698 - val_loss: 0.1850 - val_acc: 0.9506\n",
      "Epoch 22/50\n",
      "6400/6400 [==============================] - 3s 435us/step - loss: 0.0890 - acc: 0.9702 - val_loss: 0.2094 - val_acc: 0.9437\n",
      "Epoch 23/50\n",
      "6400/6400 [==============================] - 3s 463us/step - loss: 0.0880 - acc: 0.9700 - val_loss: 0.2029 - val_acc: 0.9456\n",
      "Epoch 24/50\n",
      "6400/6400 [==============================] - 3s 476us/step - loss: 0.0964 - acc: 0.9680 - val_loss: 0.1773 - val_acc: 0.9519\n",
      "Epoch 25/50\n",
      "6400/6400 [==============================] - 4s 573us/step - loss: 0.0766 - acc: 0.9748 - val_loss: 0.2088 - val_acc: 0.9469\n",
      "Epoch 26/50\n",
      "6400/6400 [==============================] - 3s 433us/step - loss: 0.0859 - acc: 0.9723 - val_loss: 0.2183 - val_acc: 0.9437\n",
      "Epoch 27/50\n",
      "6400/6400 [==============================] - 3s 454us/step - loss: 0.0841 - acc: 0.9720 - val_loss: 0.1837 - val_acc: 0.9481\n",
      "Epoch 28/50\n",
      "6400/6400 [==============================] - 3s 414us/step - loss: 0.0810 - acc: 0.9762 - val_loss: 0.1849 - val_acc: 0.9469\n",
      "Epoch 29/50\n",
      "6400/6400 [==============================] - 3s 409us/step - loss: 0.0782 - acc: 0.9741 - val_loss: 0.2022 - val_acc: 0.9481\n",
      "Epoch 30/50\n",
      "6400/6400 [==============================] - 3s 431us/step - loss: 0.0663 - acc: 0.9789 - val_loss: 0.1934 - val_acc: 0.9550\n",
      "Epoch 31/50\n",
      "6400/6400 [==============================] - 3s 438us/step - loss: 0.0747 - acc: 0.9748 - val_loss: 0.1920 - val_acc: 0.9562\n",
      "Epoch 32/50\n",
      "6400/6400 [==============================] - 3s 407us/step - loss: 0.0625 - acc: 0.9780 - val_loss: 0.1948 - val_acc: 0.9550\n",
      "Epoch 33/50\n",
      "6400/6400 [==============================] - 3s 437us/step - loss: 0.0699 - acc: 0.9755 - val_loss: 0.1905 - val_acc: 0.9537\n",
      "Epoch 34/50\n",
      "6400/6400 [==============================] - 3s 483us/step - loss: 0.0846 - acc: 0.9739 - val_loss: 0.1722 - val_acc: 0.9537\n",
      "Epoch 35/50\n",
      "6400/6400 [==============================] - 3s 438us/step - loss: 0.0691 - acc: 0.9772 - val_loss: 0.1806 - val_acc: 0.9506\n",
      "Epoch 36/50\n",
      "6400/6400 [==============================] - 3s 432us/step - loss: 0.0599 - acc: 0.9805 - val_loss: 0.1991 - val_acc: 0.9487\n",
      "Epoch 37/50\n",
      "6400/6400 [==============================] - 4s 570us/step - loss: 0.0705 - acc: 0.9758 - val_loss: 0.1863 - val_acc: 0.9562\n",
      "Epoch 38/50\n",
      "6400/6400 [==============================] - 3s 463us/step - loss: 0.0652 - acc: 0.9795 - val_loss: 0.1851 - val_acc: 0.9537\n",
      "Epoch 39/50\n",
      "6400/6400 [==============================] - 3s 483us/step - loss: 0.0639 - acc: 0.9800 - val_loss: 0.2248 - val_acc: 0.9462\n",
      "Epoch 40/50\n",
      "6400/6400 [==============================] - 3s 477us/step - loss: 0.0673 - acc: 0.9786 - val_loss: 0.1860 - val_acc: 0.9544\n",
      "Epoch 41/50\n",
      "6400/6400 [==============================] - 3s 462us/step - loss: 0.0537 - acc: 0.9816 - val_loss: 0.1962 - val_acc: 0.9556\n",
      "Epoch 42/50\n",
      "6400/6400 [==============================] - 3s 462us/step - loss: 0.0828 - acc: 0.9772 - val_loss: 0.1961 - val_acc: 0.9550\n",
      "Epoch 43/50\n",
      "6400/6400 [==============================] - 3s 448us/step - loss: 0.0641 - acc: 0.9786 - val_loss: 0.1936 - val_acc: 0.9531\n",
      "Epoch 44/50\n",
      "6400/6400 [==============================] - 3s 469us/step - loss: 0.0665 - acc: 0.9767 - val_loss: 0.2087 - val_acc: 0.9519\n",
      "Epoch 45/50\n",
      "6400/6400 [==============================] - 3s 467us/step - loss: 0.0563 - acc: 0.9817 - val_loss: 0.1829 - val_acc: 0.9600\n",
      "Epoch 46/50\n",
      "6400/6400 [==============================] - 4s 551us/step - loss: 0.0600 - acc: 0.9814 - val_loss: 0.2001 - val_acc: 0.9550\n",
      "Epoch 47/50\n",
      "6400/6400 [==============================] - 3s 449us/step - loss: 0.0533 - acc: 0.9825 - val_loss: 0.1918 - val_acc: 0.9544\n",
      "Epoch 48/50\n",
      "6400/6400 [==============================] - 3s 430us/step - loss: 0.0524 - acc: 0.9820 - val_loss: 0.2054 - val_acc: 0.9550\n",
      "Epoch 49/50\n",
      "6400/6400 [==============================] - 3s 446us/step - loss: 0.0592 - acc: 0.9808 - val_loss: 0.2156 - val_acc: 0.9531\n",
      "Epoch 50/50\n",
      "6400/6400 [==============================] - 3s 433us/step - loss: 0.0491 - acc: 0.9845 - val_loss: 0.1891 - val_acc: 0.9556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e041240>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define sequential CNN model\n",
    "model2 = Sequential()\n",
    "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
    "model2.add(e)\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Conv1D(64,3,padding='valid',activation='relu',strides=1))\n",
    "model2.add(GlobalMaxPooling1D())\n",
    "model2.add(Dense(256))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dense(8))\n",
    "model2.add(Activation('softmax'))\n",
    "# compile the model\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model2.summary())\n",
    "\n",
    "#train -test split- split into 80% for train and 20% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, labels, test_size=0.20,\n",
    "                                                    random_state=5678, stratify =labels)\n",
    "# create model\n",
    "\n",
    "# fit the model\n",
    "model2.fit(X_train, y_train, epochs=50,batch_size = 10,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3- LSTM with convolution\n",
    "- Hyperparameter Tuning - - Using Grid search CV\n",
    "- stratified K fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer = \"Adam\"):\n",
    "    model3 = Sequential()\n",
    "    model3.add(Embedding(vocab_size,10,input_length=max_length))\n",
    "    model3.add(Dropout(0.2))\n",
    "    model3.add(Conv1D(64,3,padding='valid',activation='relu',strides=1))\n",
    "    model3.add(MaxPooling1D(pool_size =2, strides =1))\n",
    "    model3.add(LSTM(100,return_sequences=True))\n",
    "    model3.add(Flatten())\n",
    "    model3.add(Dropout(0.2))\n",
    "    model3.add(Dense(256, activation = 'relu'))\n",
    "    model3.add(Dropout(0.2))\n",
    "    model3.add(Dense(8, activation = 'softmax'))\n",
    "    # compile the model\n",
    "#     optimizer = optimizer(lr = learn_rate)\n",
    "    model3.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
    "    return model3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning optimizer, batch size, epochs, learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [10,20]\n",
    "epochs = [10,30]\n",
    "optimizer = ['SGD', 'Adam']\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, optimizer = optimizer)\n",
    "\n",
    "# evaluate using 3-fold stratified cross validation\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1 )\n",
    "grid_result = grid.fit(padded_docs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.26687499888427557 using {'batch_size': 10, 'epochs': 10, 'optimizer': 'Adam'} \n",
      "\n",
      "\n",
      "0.022125000355765225 (0.02148269431754405) with: {'batch_size': 10, 'epochs': 10, 'optimizer': 'SGD'}\n",
      "0.26687499888427557 (0.03502305082875849) with: {'batch_size': 10, 'epochs': 10, 'optimizer': 'Adam'}\n",
      "0.1617500007636845 (0.016737052708153538) with: {'batch_size': 10, 'epochs': 30, 'optimizer': 'SGD'}\n",
      "0.2581249985676259 (0.03038302724473645) with: {'batch_size': 10, 'epochs': 30, 'optimizer': 'Adam'}\n",
      "0.0015000000223517418 (0.0021211215169199705) with: {'batch_size': 20, 'epochs': 10, 'optimizer': 'SGD'}\n",
      "0.2481249985396862 (0.013569146204529531) with: {'batch_size': 20, 'epochs': 10, 'optimizer': 'Adam'}\n",
      "0.0655000000409782 (0.07949717278247921) with: {'batch_size': 20, 'epochs': 30, 'optimizer': 'SGD'}\n",
      "0.254749998992309 (0.01773504950114837) with: {'batch_size': 20, 'epochs': 30, 'optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "\n",
    "print(\"Best: {0} using {1} \\n\\n\".format(grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"{0} ({1}) with: {2}\".format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
